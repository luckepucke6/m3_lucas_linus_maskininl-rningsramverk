# M3 â€“ Model Serving & Deployment Plan (Professional Workflow)

## ğŸ¯ Syfte med uppgiften

MÃ¥let Ã¤r att simulera ett professionellt arbetsflÃ¶de dÃ¤r:

- En trÃ¤nad PyTorch-modell integreras i en applikation
- Modellen exponeras via ett REST API
- Systemet containeriseras med Docker
- Arbetet sker i team med branches och code reviews

Detta handlar INTE om att fÃ¶rbÃ¤ttra modellen.

Det handlar om:
- Integration
- Separation of concerns
- API design
- Deployment readiness
- Teamarbete

Vi bygger en production-style inference microservice.

---

# ğŸ§  Ã–vergripande Arkitektur

Client  
â†“  
POST /predict  
â†“  
FastAPI  
â†“  
Model Loader (TorchScript)  
â†“  
Inference  
â†“  
JSON Response  

Modellen ska laddas EN gÃ¥ng vid startup.

---

# ğŸ“ Slutlig Projektstruktur

m3_model_serving/

app/
    main.py
    model_loader.py
    schemas.py

model/
    model.pt

Dockerfile
requirements.txt
README.md
MODEL_CONTEXT.md

---

# ğŸ—º FAS 1 â€“ Repository Setup & Struktur

## MÃ¥l
Skapa ett rent serving-repo utan training-kod.

## Steg
- Skapa nytt GitHub-repo
- Initiera lokalt repo
- Skapa mappstruktur
- Kopiera:
    - model.pt
    - MODEL_CONTEXT.md

## Definition of Done
Repo innehÃ¥ller endast serving-relaterade filer.

## FÃ¥r INTE finnas
- DVC
- Dataset
- Training loop
- CIFAR-data
- Experimentkod

---

## ğŸ” SÃ¶kord fÃ¶r att lÃ¤ra dig mer

- "monorepo vs microservice architecture"
- "clean architecture python"
- "separation of concerns backend"
- "production ML architecture overview"

---

# ğŸ—º FAS 2 â€“ Model Export & Inference Layer

## MÃ¥l
GÃ¶ra modellen production-ready via TorchScript.

## Steg
1. Exportera modell:
   torch.jit.script() eller torch.jit.trace()
2. Spara som TorchScript
3. Bygg model_loader.py:
   - Ladda modellen
   - Hantera device (CPU)
   - Konvertera input â†’ tensor
   - Returnera prediction

## Viktiga principer
- Ingen training-kod
- Inference isolerat frÃ¥n API
- Modellen laddas vid startup

## Definition of Done
Kan kÃ¶ra inference lokalt utan FastAPI.

---

## ğŸ” SÃ¶kord

- "PyTorch TorchScript tutorial"
- "torch.jit.script vs torch.jit.trace"
- "model inference best practices"
- "lazy loading vs eager loading model serving"
- "production inference optimization PyTorch"

---

# ğŸ—º FAS 3 â€“ API Design (FastAPI)

## MÃ¥l
Exponera modellen via POST /predict.

## Steg
1. Skapa schemas.py (Pydantic)
   - InputSchema
   - OutputSchema

2. Skapa main.py
   - Initiera FastAPI
   - Ladda modell globalt
   - Implementera POST /predict

3. Input:
   - JSON
   - RÃ¤tt dimensioner
   - Validering

4. Output:
   - predicted_class
   - ev. probabilities

## Definition of Done
Kan anropa API via curl och fÃ¥ korrekt svar.

---

## ğŸ” SÃ¶kord

- "FastAPI tutorial"
- "FastAPI dependency injection"
- "Pydantic request validation"
- "REST API design best practices"
- "ML model serving FastAPI"

---

# ğŸ—º FAS 4 â€“ Docker & Reproducerbarhet

## MÃ¥l
Kunna bygga och kÃ¶ra systemet via Docker.

## Steg
1. Skapa Dockerfile
   - Base image (python:3.11-slim)
   - Installera uv
   - Installera dependencies
   - Kopiera kod
   - Exponera port 8000
   - CMD uvicorn app.main:app

2. Bygg image:
   docker build -t m3-serving .

3. KÃ¶r container:
   docker run -p 8000:8000 m3-serving

4. Testa endpoint

## Definition of Done
Containern startar och svarar korrekt.

---

## ğŸ” SÃ¶kord

- "Dockerfile best practices python"
- "multi stage docker build python"
- "containerizing FastAPI"
- "uv python package manager"
- "reproducible environments Docker"

---

# ğŸ—º FAS 5 â€“ Git Workflow & Samarbete

## MÃ¥l
Arbeta som ett professionellt utvecklingsteam.

## Branch-struktur

main (skyddad)

feature/model-loader  
feature/api  
feature/docker  
feature/docs  

## Workflow

1. Skapa feature branch frÃ¥n main
2. Implementera feature
3. Testa lokalt
4. Push branch
5. Skapa Pull Request
6. Code review
7. Merge

Inga direkta commits till main.

## Code Review ska innehÃ¥lla

- Fungerar koden?
- Ã„r strukturen tydlig?
- Finns onÃ¶dig kod?
- Ã„r separation korrekt?
- Ã„r README uppdaterad?

---

## ğŸ” SÃ¶kord

- "git flow workflow"
- "pull request code review checklist"
- "branch protection rules GitHub"
- "collaborative software development best practices"

---

# ğŸ‘¥ AnsvarsfÃ¶rdelning

## Person A â€“ Modell & Inference

- TorchScript export
- model_loader.py
- Tensorhantering
- Prediction-logik

## Person B â€“ API & Infrastruktur

- schemas.py
- main.py
- Dockerfile
- requirements.txt

## BÃ¥da

- Code review
- README
- Testning
- Slutverifiering i Docker

---

# ğŸ§ª Teststrategi

Testa i tre nivÃ¥er:

1. Modell isolerat
2. API lokalt
3. API via Docker

Testa med:
- curl
- Postman
- Swagger UI

---

# ğŸ§  Viktiga Arkitekturprinciper

- Separation of concerns
- Single responsibility
- Reproducerbar miljÃ¶
- Minimal attack surface
- Stateless API

---

# ğŸ“¦ Slutleverans ska uppfylla

- Docker build fungerar
- POST /predict returnerar korrekt prediktion
- Minst tvÃ¥ Pull Requests finns
- README beskriver hur man kÃ¶r projektet

---

# ğŸš€ Vad detta trÃ¤nar infÃ¶r verkligheten

Detta Ã¤r exakt vad en ML Engineer gÃ¶r:

- Tar modell frÃ¥n data scientist
- GÃ¶r den production-ready
- Exponerar via API
- Containeriserar
- Samarbetar via Git

Detta Ã¤r skillnaden mellan:
"Jag kan trÃ¤na modeller"
och
"Jag kan deploya ML-system"